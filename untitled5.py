# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1e5tw0PMKF9A-axb2Flglp8LGO2ggYJKe

**THE SPARK FOUNDATION TASK1**

**PREDICT THE PERCENTAGE OF MARKS OF A STUDENT BASED ON NUMBER OF STUDY HOURS**

**Linear Regression with Python.
We will start with simple linear regression involving two variables
Simple Linear Regression
In this regression task we will predcit the percentage of marks student is expected to score based upon the number of hours studied.**

By: **STANLEY K Johnson**
"""

#importing libraries
import pandas as pd
import numpy as np  
import matplotlib.pyplot as plt  
get_ipython().run_line_magic('matplotlib', 'inline')

url = "http://bit.ly/w-data"
df = pd.read_csv(url)
print("Data imported:")

df.head(10)

# Plotting the distribution of scores

df.plot(x='Hours', y='Scores', style='*')  
plt.title('Hours vs Percentage')  
plt.xlabel('Hours Studied')  
plt.ylabel('Percentage Score')  
plt.show()

# From the above graph we can clearly see that there is positive linear relation between the number of hours studied and percentage of score.
# 
# Preparing the data...
# The next step is to divide th data into "attributes" (inputs) and "labels" (outputs) 
X = df.iloc[:, :-1].values
y= df.iloc[:, 1].values

# Now, we have our attributes and labels, the next step is to split this data into training and test sets. We will do this using Scikit-Learn's built in train_test_split() method
from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2, random_state = 0)

# We have to split our data into training and testing sets.


from sklearn.linear_model import LinearRegression

Regressor1 = LinearRegression()
Regressor1.fit(X,y)
print ("Training Model Done")

#Plotting the regression line
line= Regressor1.coef_*X+Regressor1.intercept_

#Plotting for test

plt.scatter(X,y)
plt.plot(X,line);
plt.show()

print(X_test)  #Testing Data
y_pred = Regressor1.predict(X_test)

# Comparing Actual vs predicted
df1= pd.DataFrame({'Actual':y_test, 'Predicted': y_pred})
df1

#Plotting the bar graph to depict the actual and predicted value
df.plot(kind= 'bar', figsize=(7,7))
plt.show()

""" *Prediction for 9.25 hr*  """

hours= 9.25
test = np.array([hours])
test=test.reshape(-1, 1)
own_pred = Regressor1.predict(test)
print("No of Hours= {}".format(hours))
print("Predicted Score= {}".format(own_pred[0]))

import numpy as np 
from sklearn import metrics
print('Mean Absolute Error: ',metrics.mean_absolute_error(y_test, y_pred))
print('Mean Squared Error: ',metrics.mean_squared_error(y_test, y_pred))
print('Root  Mean Absolute Error: ',np.sqrt(metrics.mean_absolute_error(y_test, y_pred)))
print('Explained Variance Score: ',metrics.explained_variance_score(y_test, y_pred))

# Above final step is to evaluate the performance of algorithm. This step is particularly important to compare how well different algorithms perform on particular dataset
print("Done")